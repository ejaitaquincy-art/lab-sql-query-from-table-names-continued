{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d930c89-4954-4e39-be5a-601c1dd89512",
   "metadata": {
    "id": "7d930c89-4954-4e39-be5a-601c1dd89512"
   },
   "source": [
    "# SQL query from table names - Continued"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03f026a",
   "metadata": {
    "id": "a03f026a"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_API_KEY  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a05b80-88fd-42b2-ba89-763074ae74e9",
   "metadata": {
    "id": "53a05b80-88fd-42b2-ba89-763074ae74e9"
   },
   "source": [
    "## The old Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "922f8d24",
   "metadata": {
    "id": "922f8d24"
   },
   "outputs": [],
   "source": [
    "#The old prompt\n",
    "old_context = [ {'role':'system', 'content':\"\"\"\n",
    "you are a bot to assist in create SQL commands, all your answers should start with \\\n",
    "this is your SQL, and after that an SQL that can do what the user request. \\\n",
    "Your Database is composed by a SQL database with some tables. \\\n",
    "Try to maintain the SQL order simple.\n",
    "Put the SQL command in white letters with a black background, and just after \\\n",
    "a simple and concise text explaining how it works.\n",
    "If the user ask for something that can not be solved with an SQL Order \\\n",
    "just answer something nice and simple, maximum 10 words, asking him for something that \\\n",
    "can be solved with SQL.\n",
    "\"\"\"} ]\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "first table:\n",
    "{\n",
    "  \"tableName\": \"employees\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"tipo\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"nombre\": \"name\",\n",
    "      \"tipo\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "second table:\n",
    "{\n",
    "  \"tableName\": \"salary\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"nombre\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"type\": \"date\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"salary\",\n",
    "      \"type\": \"float\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})\n",
    "\n",
    "old_context.append( {'role':'system', 'content':\"\"\"\n",
    "third table:\n",
    "{\n",
    "  \"tablename\": \"studies\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"ID\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ID_usr\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"educational_level\",\n",
    "      \"type\": \"int\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Institution\",\n",
    "      \"type\": \"varchar\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Years\",\n",
    "      \"type\": \"date\"\n",
    "    }\n",
    "    {\n",
    "      \"name\": \"Speciality\",\n",
    "      \"type\": \"varchar\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377acaae-7dd0-4d13-bc68-9e33741c231c",
   "metadata": {
    "id": "377acaae-7dd0-4d13-bc68-9e33741c231c"
   },
   "source": [
    "## New Prompt.\n",
    "We are going to improve it following the instructions of a Paper from the Ohaio University: [How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings](https://arxiv.org/abs/2305.11853). I recommend you read that paper.\n",
    "\n",
    "For each table, we will define the structure using the same syntax as in a SQL create table command, and add the sample rows of the content.\n",
    "\n",
    "Finally, at the end of the prompt, we'll include some example queries with the SQL that the model should generate. This technique is called Few-Shot Samples, in which we provide the prompt with some examples to assist it in generating the correct SQL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5334f942",
   "metadata": {
    "id": "5334f942"
   },
   "outputs": [],
   "source": [
    "context = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "You are an AI that generates SQL queries.\n",
    "\n",
    "Database schema:\n",
    "\n",
    "CREATE TABLE employees (\n",
    "    ID_usr INT,\n",
    "    name VARCHAR,\n",
    "    department VARCHAR,\n",
    "    role VARCHAR\n",
    ");\n",
    "\n",
    "CREATE TABLE salary (\n",
    "    ID_usr INT,\n",
    "    year DATE,\n",
    "    salary FLOAT\n",
    ");\n",
    "\n",
    "CREATE TABLE studies (\n",
    "    ID INT,\n",
    "    ID_usr INT,\n",
    "    educational_level VARCHAR,\n",
    "    institution VARCHAR,\n",
    "    years DATE,\n",
    "    speciality VARCHAR\n",
    ");\n",
    "\"\"\"\n",
    "}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993",
   "metadata": {
    "id": "330e69b0-3f5f-4bb2-8185-aedded2bb993"
   },
   "outputs": [],
   "source": [
    "context.append({\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "Examples:\n",
    "\n",
    "Q: Who is the highest paid employee?\n",
    "SQL:\n",
    "SELECT e.name\n",
    "FROM employees e\n",
    "JOIN salary s ON e.ID_usr = s.ID_usr\n",
    "ORDER BY s.salary DESC\n",
    "LIMIT 1;\n",
    "\n",
    "Q: What is the average salary per year?\n",
    "SQL:\n",
    "SELECT year, AVG(salary)\n",
    "FROM salary\n",
    "GROUP BY year;\n",
    "\n",
    "Q: Which institutions are associated with employees?\n",
    "SQL:\n",
    "SELECT DISTINCT institution\n",
    "FROM studies;\n",
    "\"\"\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90f417a",
   "metadata": {
    "id": "b90f417a"
   },
   "outputs": [],
   "source": [
    "#Functio to call the model.\n",
    "def return_CCRMSQL(user_message, context):\n",
    "    client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=OPENAI_API_KEY,\n",
    ")\n",
    "\n",
    "    newcontext = context.copy()\n",
    "    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=newcontext,\n",
    "            temperature=0,\n",
    "        )\n",
    "\n",
    "    return (response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c",
   "metadata": {
    "id": "9e0a4c11-dfe1-46fe-ac2b-3ff825f9749c"
   },
   "source": [
    "## NL2SQL Samples\n",
    "We're going to review some examples generated with the old prompt and others with the new prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59e8202c-ce34-487e-9037-c65a263423ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59e8202c-ce34-487e-9037-c65a263423ed",
    "outputId": "f7a97b9f-45d7-4f78-8979-a796c5bc42fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm ready to help! Please provide me with a question so I can generate the SQL query for you.\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"\"\"YOUR QUERY HERE\"\"\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c4766b1-48a9-456e-bc6c-4b6f41909aa4",
    "outputId": "029844da-5f1f-4f65-9adb-4d9c1cafacea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL: \n",
      "\n",
      "```sql\n",
      "SELECT * FROM employees;\n",
      "```\n",
      "\n",
      "Explanation: This SQL query selects all data from the \"employees\" table.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "old_context_user = old_context.copy()\n",
    "print(return_CCRMSQL(\"YOUR QUERY HERE\", old_context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "38d8d370-0524-4a28-bd54-5e5cddb08e2c",
    "outputId": "2934cdec-bea0-44db-b047-33e70dcf8ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm ready to help! Please provide me with a question so I can generate the SQL query for you.\n"
     ]
    }
   ],
   "source": [
    "#new\n",
    "print(return_CCRMSQL(\"YOUR QUERY HERE\", context_user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aa318d4-dd9f-41db-8ff4-c1d87220f766",
    "outputId": "605724a1-0d89-4ed9-d8ec-1aeeae6dc287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is your SQL:\n",
      "```sql\n",
      "\n",
      "Please provide a specific query to assist you.\n"
     ]
    }
   ],
   "source": [
    "#old\n",
    "print(return_CCRMSQL(\"YOUR QUERY HERE\", old_context_user))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47",
   "metadata": {
    "id": "0f31968e-74ad-4ae2-9537-b3d550b1be47"
   },
   "source": [
    "# Exercise\n",
    " - Complete the prompts similar to what we did in class. \n",
    "     - Try at least 3 versions\n",
    "     - Be creative\n",
    " - Write a one page report summarizing your findings.\n",
    "     - Were there variations that didn't work well? i.e., where GPT either hallucinated or wrong.\n",
    "     - What did you learn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e5d5e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL:\n",
      "SELECT e.department, AVG(s.salary) AS avg_salary\n",
      "FROM employees e\n",
      "JOIN salary s ON e.ID_usr = s.ID_usr\n",
      "GROUP BY e.department\n",
      "ORDER BY avg_salary DESC\n",
      "LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"Which department has the highest average salary?\", context_user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c2f70a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL:\n",
      "SELECT e1.name AS employee1, e2.name AS employee2, s.institution\n",
      "FROM employees e1\n",
      "JOIN studies s ON e1.ID_usr = s.ID_usr\n",
      "JOIN employees e2 ON e1.ID_usr != e2.ID_usr\n",
      "JOIN studies s2 ON e2.ID_usr = s2.ID_usr AND s.institution = s2.institution;\n"
     ]
    }
   ],
   "source": [
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"Find employees who studied at the same institution\", context_user))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "250503ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL:\n",
      "SELECT st.speciality\n",
      "FROM studies st\n",
      "JOIN salary s ON st.ID_usr = s.ID_usr\n",
      "ORDER BY s.salary DESC\n",
      "LIMIT 1;\n"
     ]
    }
   ],
   "source": [
    "context_user = context.copy()\n",
    "print(return_CCRMSQL(\"Which specialization is linked to the highest salaries?\", context_user))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06b76e",
   "metadata": {},
   "source": [
    "## Findings Report (One Page)\n",
    "\n",
    "### What I tested\n",
    "- I tested **two prompting approaches** for text-to-SQL:\n",
    "  - **Old prompt**: long natural-language instructions + table info written in a loose format\n",
    "  - **New prompt**: explicit `CREATE TABLE` schema + **few-shot examples**\n",
    "- I then ran **3 additional “creative” prompts** (Exercise section) to see how well the model generalized.\n",
    "\n",
    "### Results and observations\n",
    "- **New prompt worked better overall**\n",
    "  - Output SQL was **more structured** and usually **syntactically correct**\n",
    "  - The model was more consistent at:\n",
    "    - selecting the right tables\n",
    "    - adding JOINs on `ID_usr`\n",
    "    - using `GROUP BY` and `AVG()` when asked for “average”\n",
    "- **Few-shot examples improved reliability**\n",
    "  - The examples acted like “templates”\n",
    "  - The model copied the style:\n",
    "    - `JOIN` patterns\n",
    "    - ordering and limiting results\n",
    "    - using `DISTINCT` when needed\n",
    "\n",
    "### Variations that did not work well (hallucinations / wrong logic)\n",
    "- **Ambiguous requests produced assumptions**\n",
    "  - When a question required interpretation (for example “specialization linked to highest salaries”), the model sometimes:\n",
    "    - assumed relationships not explicitly stated\n",
    "    - selected columns that might not exist\n",
    "    - mixed up what should be grouped vs. filtered\n",
    "- **Typical failure patterns**\n",
    "  - missing a JOIN when it was logically required\n",
    "  - grouping errors (missing `GROUP BY` while using aggregates)\n",
    "  - using a field name that looks plausible but is not in the schema\n",
    "\n",
    "### What I learned\n",
    "- Prompt clarity has a **direct impact** on SQL correctness.\n",
    "- Explicit schema in `CREATE TABLE` format reduces hallucination.\n",
    "- Few-shot examples reduce structural mistakes and improve consistency.\n",
    "- Ambiguity increases the chance the model invents logic or fields.\n",
    "- Best practice: **schema + examples + precise question wording** gives the most reliable text-to-SQL output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c64ccff",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
